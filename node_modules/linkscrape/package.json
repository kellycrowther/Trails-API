{
  "_args": [
    [
      {
        "raw": "linkscrape",
        "scope": null,
        "escapedName": "linkscrape",
        "name": "linkscrape",
        "rawSpec": "",
        "spec": "latest",
        "type": "tag"
      },
      "/Users/kelly/Documents/Trails-API"
    ]
  ],
  "_from": "linkscrape@latest",
  "_id": "linkscrape@1.0.0",
  "_inCache": true,
  "_location": "/linkscrape",
  "_nodeVersion": "0.10.32",
  "_npmUser": {
    "name": "jprichardson",
    "email": "jprichardson@gmail.com"
  },
  "_npmVersion": "2.3.0",
  "_phantomChildren": {
    "boolbase": "1.0.0",
    "dom-serializer": "0.1.0",
    "domelementtype": "1.3.0",
    "entities": "1.1.1",
    "htmlparser2": "3.8.3",
    "nth-check": "1.0.1"
  },
  "_requested": {
    "raw": "linkscrape",
    "scope": null,
    "escapedName": "linkscrape",
    "name": "linkscrape",
    "rawSpec": "",
    "spec": "latest",
    "type": "tag"
  },
  "_requiredBy": [
    "#USER"
  ],
  "_resolved": "https://registry.npmjs.org/linkscrape/-/linkscrape-1.0.0.tgz",
  "_shasum": "0c882d41a569a3cc4b540e29a8d442d0ef38a1cf",
  "_shrinkwrap": null,
  "_spec": "linkscrape",
  "_where": "/Users/kelly/Documents/Trails-API",
  "author": {
    "name": "JP Richardson",
    "email": "jprichardson@gmail.com"
  },
  "bugs": {
    "url": "https://github.com/jprichardson/node-linkscrape/issues"
  },
  "dependencies": {
    "cheerio": "^0.19.0"
  },
  "description": "A Node.js module to scrape and normalize links from an HTML string.",
  "devDependencies": {
    "mocha": "*"
  },
  "directories": {},
  "dist": {
    "shasum": "0c882d41a569a3cc4b540e29a8d442d0ef38a1cf",
    "tarball": "https://registry.npmjs.org/linkscrape/-/linkscrape-1.0.0.tgz"
  },
  "gitHead": "d4a785684fa61cb702c8c92888c7d577fad4d9e7",
  "homepage": "https://github.com/jprichardson/node-linkscrape",
  "keywords": [
    "extract",
    "scrape",
    "html",
    "link",
    "anchor",
    "body",
    "scraper",
    "http"
  ],
  "licenses": [
    {
      "type": "MIT",
      "url": "http://github.com/jprichardson/node-linkscrape/raw/master/LICENSE"
    }
  ],
  "main": "./lib/linkscrape",
  "maintainers": [
    {
      "name": "jprichardson",
      "email": "jprichardson@gmail.com"
    }
  ],
  "name": "linkscrape",
  "optionalDependencies": {},
  "readme": "\nNode.js - linkscrape\n=====================\n\n[![build status](https://secure.travis-ci.org/jprichardson/node-linkscrape.png)](http://travis-ci.org/jprichardson/node-linkscrape)\n \nThis module allows scrapes links from an HTML string and normalizes them. It does not actually perform the HTTP request. Use [superagent][1] or [request][2] for that.\n\n\nInstallation\n------------\n\n    npm install linkscrape\n\n\n\nExample\n-------\n\nHTML string:\n```html\n<html>\n  <head>\n    <title>\n      Test File\n    </title>\n  </head>\n  <body>\n    <p id=\"wat\">\n      <a href=\"http://google.com\"><b>Google</b></a>\n    </p>\n    <p>\n      <a href=\"#wat\" class=\"pretty\">Link in page</a>\n      <a href=\"javascript:alert('hi');\">hi</a>\n      <a href=\"alert('hello')\">hello</a>\n      <a href=\"/faq/questions\">Faq</a>\n      <a href=\"aboutus\">About Us</a>\n    </p>\n  </body>\n</html>\n```\n\nYou must pass in the URL (of where the HTML string came from) to the `scrape()` method so that it can normalize the links.\n\n```javascript\nvar linkscrape = require('linkscrape');\n\nlinkscrape('http://someserver.com/mypage', htmlString, function(links, $){\n  console.log(links.length);// is 6\n\n  console.log(links[0].href); //is 'http://google.com'\n  console.log(links[0].text); //is 'Google'\n  console.log(links[0].html); //is '<b>Google</b>'\n  console.log(links[0].element); //object\n  console.log(links[0].link); //is 'http://google.com'\n\n  console.log(links[1].href); //is '#wat'\n  console.log(links[1].text); //is 'Link in page'\n  console.log(links[1].html); //is 'Link in page'\n  console.log(links[1].element); //object\n  console.log(links[1].link); //is null\n  console.log($(links[1].element).attr('class')); //is 'pretty'\n\n  console.log(links[2].href); //is \"javascript:alert('hi');\"\n  console.log(links[2].text); //is 'hi'\n  console.log(links[2].html); //is 'hi'\n  console.log(links[2].element); //object\n  console.log(links[2].link); //is null\n\n  console.log(links[3].href); //is \"alert('hello')\"\n  console.log(links[3].text); //is 'hello'\n  console.log(links[3].html); //is 'hello'\n  console.log(links[3].element); //object\n  console.log(links[3].link); //is null\n\n  console.log(links[4].href); //is \"/faq/questions\"\n  console.log(links[4].text); //is 'Faq'\n  console.log(links[4].html); //is 'Faq'\n  console.log(links[4].element); //object\n  console.log(links[4].link); //is 'http://someserver.com/faq/questions'\n\n  console.log(links[5].href); //is \"aboutus\"\n  console.log(links[5].text); //is 'About Us'\n  console.log(links[5].html); //is 'About Us'\n  console.log(links[5].element); //object\n  console.log(links[5].link); //is 'http://someserver.com/aboutus'\n});\n```\n\nIt's currently backed by [cheerio][3]. So you can use the `$` with the jQuery selectors. See [cheerio docs][3] for more details. \n\n\n\nTest\n----\n\n    npm test\n\nor...\n\n    mocha test\n\n\n\nLicense\n-------\n\nLicensed under MIT. See `LICENSE` for more details.\n\nCopyright (c) 2012 JP Richardson\n\n\n[1]:http://visionmedia.github.com/superagent/\n[2]:https://github.com/mikeal/request\n[3]:https://github.com/MatthewMueller/cheerio\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/jprichardson/node-linkscrape.git"
  },
  "scripts": {
    "test": "mocha test"
  },
  "version": "1.0.0"
}
